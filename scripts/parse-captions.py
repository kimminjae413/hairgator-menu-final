# -*- coding: utf-8 -*-
"""
ëª…ë ¹ 1-2: ìë§‰ íŒŒì‹± ë° ìš©ì–´ ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸
- ìë§‰ íŒŒì¼ì—ì„œ ê¸°ì¥, í˜•íƒœ, ì§ˆê°, ì•ë¨¸ë¦¬, ë‚œì´ë„ ì¶”ì¶œ
- ì •ê·œí™”ëœ ìš©ì–´ ë§¤í•‘
"""

import os
import sys
import json
import re

sys.stdout.reconfigure(encoding='utf-8')

# ë°ì´í„°ì…‹ ê²½ë¡œ
BASE_PATH = r"C:\Users\ê¹€ë¯¼ì¬\Desktop\2. í—¤ì–´ê²Œì´í„°_ì´ë¡ -20251105T045428Z-1-001\women_cut_recipe"
SERIES = ["FAL", "FBL", "FCL", "FDL", "FEL", "FFL", "FGL", "FHL"]

# ìš©ì–´ ì •ê·œí™” ë§¤í•‘
NORMALIZATION = {
    "length": {
        "ìˆ": "SHORT",
        "ì‡¼íŠ¸": "SHORT",
        "ë¯¸ë””ì—„": "MEDIUM",
        "ë¯¸ë””ì—„ ìˆ": "MEDIUM_SHORT",
        "ë¯¸ë””ì—„ ë¡±": "MEDIUM_LONG",
        "ë¡±": "LONG",
        "ì„¸ë¯¸ë¡±": "SEMI_LONG"
    },
    "shape": {
        "ì›ë­ìŠ¤": "ONE_LENGTH",
        "ê·¸ë ˆì¥¬ì—ì´ì…˜": "GRADUATION",
        "ê·¸ë¼ë°ì´ì…˜": "GRADUATION",
        "ë ˆì´ì–´": "LAYER",
        "ìŠ¤í€˜ì–´ ë ˆì´ì–´": "SQUARE_LAYER",
        "ë¼ìš´ë“œ ë ˆì´ì–´": "ROUND_LAYER",
        "ìœ ë‹ˆí¼ ë ˆì´ì–´": "UNIFORM_LAYER",
        "ì¸í¬ë¦¬ìŠ¤ ë ˆì´ì–´": "INCREASE_LAYER",
        "ë””ìŠ¤ì»¤ë„¥ì…˜": "DISCONNECTION",
        "ë³µí•©í˜•": "COMBINED",
        "ì•„ì´ë¡± ìŠ¤íƒ€ì¼": "IRON_STYLE"
    },
    "texture": {
        "ë¸”ëŸ°íŠ¸": "BLUNT",
        "ìœ„ë¹™": "WEAVING",
        "ìŠ¬ë¼ì´ì‹±": "SLICING",
        "í¬ì¸íŠ¸ ì»·": "POINT_CUT",
        "í¬ì¸íŠ¸ì»·": "POINT_CUT",
        "ìŠ¤íŠ¸ë¡ ì»¤íŠ¸": "STROKE_CUT",
        "ì„¸ë‹ˆì»·": "THINNING",
        "ì„¸ë‹ˆ ì»·": "THINNING",
        "í‹´ë‹": "THINNING",
        "ë ˆì´ì €": "RAZOR",
        "ë ˆì´ì € ì»·": "RAZOR",
        "ì±± ì»·": "CHOP_CUT",
        "íŠ¸ìœ„ìŠ¤íŠ¸": "TWIST",
        "í…ìŠ¤ì³": "TEXTURE"
    },
    "bangs": {
        "ì—†ìŒ": "NONE",
        "í’€ë±…": "FULL_BANG",
        "ì‹œìŠ¤ë£¨ë±…": "SEE_THROUGH",
        "ì‹œìŠ¤ë£¨ ë±…": "SEE_THROUGH",
        "ì‚¬ì´ë“œë±…": "SIDE_BANG",
        "ì‚¬ì´ë“œ ë±…": "SIDE_BANG",
        "ì»¤íŠ¼ë±…": "CURTAIN_BANG",
        "ì»¤íŠ¼ ë±…": "CURTAIN_BANG",
        "í˜ì´ìŠ¤ í”„ë ˆì´ë°": "FACE_FRAMING",
        "í˜ì´ìŠ¤í”„ë ˆì´ë°": "FACE_FRAMING",
        "ê¸´ ì•ë¨¸ë¦¬": "LONG_BANG",
        "ì§§ì€ ì•ë¨¸ë¦¬": "SHORT_BANG",
        "ë² ì´ë¹„ë±…": "BABY_BANG",
        "Mìë±…": "M_BANG"
    },
    "difficulty": {
        "ì‰¬ì›€": "EASY",
        "ë³´í†µ": "MEDIUM",
        "ì–´ë ¤ì›€": "HARD",
        "ë§¤ìš° ì–´ë ¤ì›€": "VERY_HARD"
    }
}

def parse_caption(text, style_id):
    """ìë§‰ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜

    ìë§‰ ë‚´ìš©ì´ ê¸°ìˆ ì  ì„¤ëª…ì¸ ê²½ìš°:
    - ìŠ¤íƒ€ì¼ ì½”ë“œì—ì„œ ê¸°ì¥ ì¶”ë¡  (A=ìˆ, B=ë¯¸ë””ì—„ìˆ, C=ë¯¸ë””ì—„, D=ë¯¸ë””ì—„ë¡±, E=ë¡±, F=ì„¸ë¯¸ë¡±, G=ë¡±, H=ì—‘ìŠ¤íŠ¸ë¼ë¡±)
    - í…ìŠ¤íŠ¸ì—ì„œ í˜•íƒœ í‚¤ì›Œë“œ ì¶”ì¶œ (ì›ë­ìŠ¤, ê·¸ë˜ì¥¬ì—ì´ì…˜, ë ˆì´ì–´ ë“±)
    """
    result = {
        "raw": text.strip(),
        "length": None,
        "length_normalized": None,
        "shape": None,
        "shape_normalized": None,
        "texture": None,
        "texture_normalized": None,
        "bangs": None,
        "bangs_normalized": None,
        "difficulty": None,
        "difficulty_normalized": None,
        "techniques": []
    }

    # 1. ë¨¼ì € êµ¬ì¡°í™”ëœ í˜•ì‹ ì²´í¬ (ê¸°ì¥:, í˜•íƒœ: ë“±)
    patterns = {
        "length": r"ê¸°ì¥\s*[:ï¼š]\s*([^,ï¼Œ]+)",
        "shape": r"í˜•íƒœ\s*[:ï¼š]\s*([^,ï¼Œ]+)",
        "texture": r"ì§ˆê°\s*[:ï¼š]\s*([^,ï¼Œ]+)",
        "bangs": r"ì•ë¨¸ë¦¬\s*[:ï¼š]\s*([^,ï¼Œ]+)",
        "difficulty": r"(?:ì»·\s*)?ë‚œì´ë„\s*[:ï¼š]\s*([^,ï¼Œ]+)"
    }

    has_structured = False
    for field, pattern in patterns.items():
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            has_structured = True
            value = match.group(1).strip()
            result[field] = value
            norm_map = NORMALIZATION.get(field, {})
            for kr_term, en_code in norm_map.items():
                if kr_term in value:
                    result[f"{field}_normalized"] = en_code
                    break

    # 2. êµ¬ì¡°í™”ëœ í˜•ì‹ì´ ì—†ìœ¼ë©´ ê¸°ìˆ ì  ìë§‰ì—ì„œ ì¶”ì¶œ
    if not has_structured:
        # ìŠ¤íƒ€ì¼ ì½”ë“œì—ì„œ ê¸°ì¥ ì¶”ë¡  (F + ë‘ë²ˆì§¸ ê¸€ì)
        # FAL = A(ìˆ), FBL = B(ë¯¸ë””ì—„ìˆ), FCL = C(ë¯¸ë””ì—„), FDL = D(ë¯¸ë””ì—„ë¡±)
        # FEL = E(ë¡±), FFL = F(ì„¸ë¯¸ë¡±), FGL = G(ë¡±), FHL = H(ì—‘ìŠ¤íŠ¸ë¼ë¡±)
        length_map = {
            'A': ('ìˆ', 'SHORT'),
            'B': ('ë¯¸ë””ì—„ ìˆ', 'MEDIUM_SHORT'),
            'C': ('ë¯¸ë””ì—„', 'MEDIUM'),
            'D': ('ë¯¸ë””ì—„ ë¡±', 'MEDIUM_LONG'),
            'E': ('ë¡±', 'LONG'),
            'F': ('ì„¸ë¯¸ë¡±', 'SEMI_LONG'),
            'G': ('ë¡±', 'LONG'),
            'H': ('ì—‘ìŠ¤íŠ¸ë¼ ë¡±', 'EXTRA_LONG')
        }

        if len(style_id) >= 2:
            length_code = style_id[1]  # F'A'L0001 -> 'A'
            if length_code in length_map:
                result["length"], result["length_normalized"] = length_map[length_code]

        # í…ìŠ¤íŠ¸ì—ì„œ í˜•íƒœ í‚¤ì›Œë“œ ì¶”ì¶œ
        shape_keywords = [
            ("ì›ë­ìŠ¤", "ONE_LENGTH"),
            ("ê·¸ë˜ì¥¬ì—ì´ì…˜", "GRADUATION"),
            ("ê·¸ë ˆì¥¬ì—ì´ì…˜", "GRADUATION"),
            ("ìŠ¤í€˜ì–´ ë ˆì´ì–´", "SQUARE_LAYER"),
            ("ìŠ¤í€˜ì–´ë ˆì´ì–´", "SQUARE_LAYER"),
            ("ìŠ¤í€˜ì–´ ì»¤íŠ¸", "SQUARE_CUT"),
            ("ìŠ¤í€˜ì–´ì»¤íŠ¸", "SQUARE_CUT"),
            ("ë ˆì´ì–´", "LAYER"),
            ("ë””ìŠ¤ì»¤ë„¥ì…˜", "DISCONNECTION"),
        ]

        detected_shapes = []
        for kr, en in shape_keywords:
            if kr in text:
                detected_shapes.append((kr, en))

        if detected_shapes:
            # ê°€ì¥ êµ¬ì²´ì ì¸ ê²ƒ ì„ íƒ (ê¸€ììˆ˜ê°€ ê¸´ ê²ƒ)
            detected_shapes.sort(key=lambda x: -len(x[0]))
            result["shape"], result["shape_normalized"] = detected_shapes[0]

        # ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ (89ìš©ì–´ ê¸°ë°˜)
        tech_keywords = {
            # ì„¹ì…˜ (70ë²ˆ ìš©ì–´)
            "ê°€ë¡œì„¹ì…˜": "HS",
            "ì„¸ë¡œì„¹ì…˜": "VS",
            "í›„ëŒ€ê° ì„¹ì…˜": "DBS",
            "í›„ëŒ€ê°ì„¹ì…˜": "DBS",
            "ì „ëŒ€ê° ì„¹ì…˜": "DFS",
            "ì „ëŒ€ê°ì„¹ì…˜": "DFS",
            "íŒŒì´ì„¹ì…˜": "PIE",

            # ë””ìì¸ë¼ì¸ (31ë²ˆ ìš©ì–´)
            "ê³ ì • ë””ìì¸ë¼ì¸": "STATIONARY_DL",
            "ê³ ì •ë””ìì¸ë¼ì¸": "STATIONARY_DL",
            "ê³ ì • ë””ìì¸ ë¼ì¸": "STATIONARY_DL",
            "ì´ë™ ë””ìì¸ë¼ì¸": "MOBILE_DL",
            "ì´ë™ë””ìì¸ë¼ì¸": "MOBILE_DL",
            "ì´ë™ ë””ìì¸ ë¼ì¸": "MOBILE_DL",
            "í˜¼í•© ë””ìì¸ë¼ì¸": "COMBINATION_DL",
            "í˜¼í•©ë””ìì¸ë¼ì¸": "COMBINATION_DL",
            "í˜¼í•© ë””ìì¸ ë¼ì¸": "COMBINATION_DL",

            # ê°ë„ (54ë²ˆ, 33ë²ˆ ìš©ì–´)
            "ì²œì²´ì¶•": "CELESTIAL_AXIS",
            "ì²œì²´ì¶•ê°ë„": "CELESTIAL_AXIS",
            "ì²œì²´ì¶• ê°ë„": "CELESTIAL_AXIS",
            "ë‹¤ì´ë ‰ì…˜": "DIRECTION",
            "ë¦¬í”„íŠ¸": "LIFTING",

            # ë¶„ë°° (35ë²ˆ ìš©ì–´)
            "ë³€ì´ë¶„ë°°": "SHIFTED_DIST",
            "ë³€ì´ ë¶„ë°°": "SHIFTED_DIST",

            # ì»¤íŒ… ê¸°ë²• (19, 81ë²ˆ ë“±)
            "í¬ì¸íŠ¸ì»·": "POINT_CUT",
            "í¬ì¸íŠ¸ ì»·": "POINT_CUT",
            "ë¸”ëŸ°íŠ¸": "BLUNT",
            "ë¸”ëŸ°íŠ¸ì»·": "BLUNT_CUT",
            "ìœ„ë¹™": "WEAVING",
            "ìŠ¬ë¼ì´ì‹±": "SLICING",
            "ìŠ¤í€˜ì–´ì»¤íŠ¸": "SQUARE_CUT",
            "ìŠ¤í€˜ì–´ ì»¤íŠ¸": "SQUARE_CUT",
        }

        for kw, code in tech_keywords.items():
            if kw in text:
                if code not in result["techniques"]:
                    result["techniques"].append(code)

    return result

def main():
    print("=" * 70)
    print("ìë§‰ íŒŒì‹± ë° ìš©ì–´ ì¶”ì¶œ")
    print("=" * 70)

    all_parsed = []
    stats = {
        "total": 0,
        "parsed": 0,
        "length": {},
        "shape": {},
        "texture": {},
        "bangs": {},
        "difficulty": {}
    }

    for series in SERIES:
        series_path = os.path.join(BASE_PATH, series)
        if not os.path.exists(series_path):
            continue

        style_folders = sorted([d for d in os.listdir(series_path)
                               if os.path.isdir(os.path.join(series_path, d))])

        print(f"\nğŸ“ {series} ì‹œë¦¬ì¦ˆ: {len(style_folders)}ê°œ")
        print("-" * 50)

        for style_id in style_folders:
            style_path = os.path.join(series_path, style_id)
            stats["total"] += 1

            # ìë§‰ íŒŒì¼ ì°¾ê¸°
            caption_file = None
            for pattern in [f"{style_id}(ìë§‰).txt", f"{style_id}-jamag.txt",
                           f"{style_id}_ìë§‰.txt", f"{style_id}.txt"]:
                fp = os.path.join(style_path, pattern)
                if os.path.exists(fp):
                    caption_file = fp
                    break

            if not caption_file:
                print(f"  âŒ {style_id}: ìë§‰ ì—†ìŒ")
                continue

            # íŒŒì‹±
            try:
                with open(caption_file, 'r', encoding='utf-8') as f:
                    text = f.read()

                parsed = parse_caption(text, style_id)
                parsed["styleId"] = style_id
                parsed["series"] = series
                all_parsed.append(parsed)
                stats["parsed"] += 1

                # í†µê³„ ìˆ˜ì§‘
                for field in ["length", "shape", "texture", "bangs", "difficulty"]:
                    val = parsed.get(f"{field}_normalized") or parsed.get(field) or "UNKNOWN"
                    stats[field][val] = stats[field].get(val, 0) + 1

                print(f"  âœ… {style_id}: {parsed['length']} | {parsed['shape']} | {parsed['texture']}")

            except Exception as e:
                print(f"  âŒ {style_id}: íŒŒì‹± ì˜¤ë¥˜ - {e}")

    # í†µê³„ ì¶œë ¥
    print("\n" + "=" * 70)
    print("ğŸ“Š ìš©ì–´ ë¶„í¬ í†µê³„")
    print("=" * 70)

    for field in ["length", "shape", "texture", "bangs", "difficulty"]:
        print(f"\nâ–  {field.upper()}:")
        for val, cnt in sorted(stats[field].items(), key=lambda x: -x[1]):
            print(f"   {val}: {cnt}ê°œ")

    # JSON ì €ì¥
    output_path = os.path.join(os.path.dirname(__file__), "parsed-captions.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({
            "total": stats["total"],
            "parsed": stats["parsed"],
            "distribution": {
                "length": stats["length"],
                "shape": stats["shape"],
                "texture": stats["texture"],
                "bangs": stats["bangs"],
                "difficulty": stats["difficulty"]
            },
            "styles": all_parsed
        }, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ íŒŒì‹± ê²°ê³¼ ì €ì¥: {output_path}")
    print(f"\nâœ… ì™„ë£Œ: {stats['parsed']}/{stats['total']}ê°œ ìŠ¤íƒ€ì¼ íŒŒì‹±ë¨")

if __name__ == "__main__":
    main()
